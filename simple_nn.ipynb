{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_sets = ['O', 'S'] # O-> Set B (Normal ), S-> Set E (Seizure)\n",
    "label_sets = [0,1] # 0->Normal, 1-> Seizure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is in folders 'input/O, input/S' etc.\n",
    "data=[]\n",
    "labels = []\n",
    "for file_set, label in zip(file_sets, label_sets):\n",
    "    for file in glob.glob('input/'+ file_set +'/*.txt'):\n",
    "        with open(file) as f:\n",
    "            int_list = [int(x) for x in f]\n",
    "            data.append(int_list)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4097)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "labels = np.asarray(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the data\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (160, 4097)\n",
      "y_train shape: (160,)\n",
      "x_val shape: (40, 4097)\n",
      "y_val shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and validation set\n",
    "training_samples = 160\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples:]\n",
    "y_val = labels[training_samples:]\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_val shape:', x_val.shape)\n",
    "print('y_val shape:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1000, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(layers.Dense(500, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 1s - loss: 6.7878 - acc: 0.5062 - val_loss: 5.9390 - val_acc: 0.5500\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 0s - loss: 4.8736 - acc: 0.6375 - val_loss: 5.5856 - val_acc: 0.5500\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s - loss: 4.0891 - acc: 0.7125 - val_loss: 4.9859 - val_acc: 0.5750\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s - loss: 3.6493 - acc: 0.7625 - val_loss: 4.9152 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s - loss: 3.6154 - acc: 0.7625 - val_loss: 4.8549 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s - loss: 3.2732 - acc: 0.7875 - val_loss: 4.8516 - val_acc: 0.5750\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s - loss: 3.1946 - acc: 0.8000 - val_loss: 4.9074 - val_acc: 0.5750\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s - loss: 3.1036 - acc: 0.8000 - val_loss: 4.9642 - val_acc: 0.5750\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 0s - loss: 3.0938 - acc: 0.8063 - val_loss: 4.9757 - val_acc: 0.5750\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 0s - loss: 3.0937 - acc: 0.8063 - val_loss: 4.9881 - val_acc: 0.5750\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 0s - loss: 3.0936 - acc: 0.8063 - val_loss: 4.9978 - val_acc: 0.5750\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 0s - loss: 3.0935 - acc: 0.8063 - val_loss: 5.0106 - val_acc: 0.5750\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 0s - loss: 3.0935 - acc: 0.8063 - val_loss: 5.0227 - val_acc: 0.5750\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 0s - loss: 3.0934 - acc: 0.8063 - val_loss: 5.0375 - val_acc: 0.5750\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 0s - loss: 3.0934 - acc: 0.8063 - val_loss: 5.3607 - val_acc: 0.5750\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 0s - loss: 2.8942 - acc: 0.8187 - val_loss: 5.3452 - val_acc: 0.5750\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 0s - loss: 2.7966 - acc: 0.8250 - val_loss: 5.3749 - val_acc: 0.5500\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 0s - loss: 2.6949 - acc: 0.8312 - val_loss: 5.3726 - val_acc: 0.5500\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 0s - loss: 2.6948 - acc: 0.8312 - val_loss: 5.3747 - val_acc: 0.5500\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 0s - loss: 2.6948 - acc: 0.8312 - val_loss: 5.3746 - val_acc: 0.5500\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3752 - val_acc: 0.5500\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3748 - val_acc: 0.5500\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3768 - val_acc: 0.5500\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3805 - val_acc: 0.5500\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3830 - val_acc: 0.5500\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3857 - val_acc: 0.5500\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3888 - val_acc: 0.5500\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3945 - val_acc: 0.5500\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.3980 - val_acc: 0.5500\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.4020 - val_acc: 0.5500\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 0s - loss: 2.6947 - acc: 0.8312 - val_loss: 5.6694 - val_acc: 0.5500\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 0s - loss: 2.4973 - acc: 0.8438 - val_loss: 5.4274 - val_acc: 0.5500\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 0s - loss: 2.4955 - acc: 0.8438 - val_loss: 5.4341 - val_acc: 0.5500\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 0s - loss: 2.4955 - acc: 0.8438 - val_loss: 5.4410 - val_acc: 0.5500\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 0s - loss: 2.4955 - acc: 0.8438 - val_loss: 5.4476 - val_acc: 0.5500\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.4531 - val_acc: 0.5500\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.4592 - val_acc: 0.5500\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.4655 - val_acc: 0.5500\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.4735 - val_acc: 0.5500\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.4794 - val_acc: 0.5500\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.4864 - val_acc: 0.5500\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.4921 - val_acc: 0.5500\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5035 - val_acc: 0.5500\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5111 - val_acc: 0.5500\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5162 - val_acc: 0.5500\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5233 - val_acc: 0.5500\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5326 - val_acc: 0.5500\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5251 - val_acc: 0.5500\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5321 - val_acc: 0.5500\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5378 - val_acc: 0.5500\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.5427 - val_acc: 0.5500\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 0s - loss: 2.4954 - acc: 0.8438 - val_loss: 5.4132 - val_acc: 0.5250\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 0s - loss: 2.1882 - acc: 0.8500 - val_loss: 5.4113 - val_acc: 0.5250\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 0s - loss: 1.6936 - acc: 0.8875 - val_loss: 5.5835 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 0s - loss: 1.5596 - acc: 0.9000 - val_loss: 5.4683 - val_acc: 0.5250\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4670 - val_acc: 0.5250\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4687 - val_acc: 0.5250\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4707 - val_acc: 0.5250\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4705 - val_acc: 0.5250\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4726 - val_acc: 0.5250\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4726 - val_acc: 0.5250\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4731 - val_acc: 0.5250\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4755 - val_acc: 0.5250\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4754 - val_acc: 0.5250\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4750 - val_acc: 0.5250\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4746 - val_acc: 0.5250\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4748 - val_acc: 0.5250\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4739 - val_acc: 0.5250\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4734 - val_acc: 0.5250\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4723 - val_acc: 0.5250\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4752 - val_acc: 0.5250\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4738 - val_acc: 0.5250\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4738 - val_acc: 0.5250\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4707 - val_acc: 0.5250\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4703 - val_acc: 0.5250\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4702 - val_acc: 0.5250\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4685 - val_acc: 0.5250\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4634 - val_acc: 0.5250\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4647 - val_acc: 0.5250\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4633 - val_acc: 0.5250\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4621 - val_acc: 0.5250\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4643 - val_acc: 0.5250\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4621 - val_acc: 0.5250\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4621 - val_acc: 0.5250\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4619 - val_acc: 0.5250\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4619 - val_acc: 0.5250\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4639 - val_acc: 0.5250\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4617 - val_acc: 0.5250\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4613 - val_acc: 0.5250\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4600 - val_acc: 0.5250\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4622 - val_acc: 0.5250\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4592 - val_acc: 0.5250\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4597 - val_acc: 0.5250\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.9964 - acc: 0.937 - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4615 - val_acc: 0.5250\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 0s - loss: 1.4990 - acc: 0.9062 - val_loss: 5.4643 - val_acc: 0.5500\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 0s - loss: 1.3994 - acc: 0.9125 - val_loss: 5.4542 - val_acc: 0.5500\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 0s - loss: 1.3994 - acc: 0.9125 - val_loss: 5.4469 - val_acc: 0.5500\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 0s - loss: 1.3994 - acc: 0.9125 - val_loss: 5.4400 - val_acc: 0.5500\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 0s - loss: 1.3994 - acc: 0.9125 - val_loss: 5.4360 - val_acc: 0.5500\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 0s - loss: 1.3994 - acc: 0.9125 - val_loss: 5.4302 - val_acc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f541e8657b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
